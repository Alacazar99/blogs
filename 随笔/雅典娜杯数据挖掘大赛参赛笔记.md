```
import pandas as pd

# 读取 用户基本信息 ptrain_profile.csv 数据
def load_train_data():
    return pd.read_csv('problems/problem_1/train/train_profile.csv')

train_profile = load_train_data()

# 脱敏数据的数量规划。
print(train_profile["职业"].value_counts()/len(train_profile))
# print(train_profile["教育程度"].value_counts()/len(train_profile))
# print(train_profile["婚姻状态"].value_counts()/len(train_profile))
# print(train_profile["户口类型"].value_counts()/len(train_profile))
train_profile.head()
# train_profile.describe()
```

```
# 读取 银行卡流水 bankStatement.csv 数据
def load_bankStatement_data():
    return pd.read_csv('problems/problem_1/train/train_bankStatement.csv')

banksstatement = load_bankStatement_data()
# 脱敏数据的数量统计。
print(banksstatement["交易类型"].value_counts())
print(banksstatement["工资收入标记"].value_counts())

banksstatement.head(10)
# banksstatement.describe()
```

```
# 读取 信用卡账单 creditBill.csv 数据
def load_creditBill_data():
    return pd.read_csv('problems/problem_1/train/train_creditBill.csv')

creditBill = load_creditBill_data()
# 脱敏数据的数量统计。
print(banksstatement["交易类型"].value_counts())
print(banksstatement["工资收入标记"].value_counts())
# print(banksstatement["银行标识"].value_counts())
creditBill.head(5)
# creditBill.describe()
```
```
# 读取 行为记录 behaviors.csv 数据
def load_behaviors_data():
    return pd.read_csv('problems/problem_1/train/train_behaviors.csv')

behaviors = load_behaviors_data()
behaviors.head()
# behaviors.describe()
```
```
# 读取 逾期标签 label.csv 数据
def load_label_data():
    return pd.read_csv('problems/problem_1/train/train_label.csv')

label = load_label_data()

# 脱敏数据的数量统计。

print(label["标签"].value_counts()/len(label))
label.head()
# label.describe()
```

```
# 数据表连接:
import pandas as pd
list_data1 = pd.merge(train_profile,banksstatement,how='left')
list_data = pd.merge(creditBill,list_data1,how='left')

# creditBill.head()
list_data.head()
```
## 数据集分割
```
from sklearn.model_selection import train_test_split

def feature_label_split(dataset):
    y = dataset['标签'].values
    X = dataset.drop(['标签'], axis=1).values
    return X, y

X, y = feature_label_split(dataset_prepard)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
X_train.shape, X_test.shape, y_train.shape, y_test.shape
```
# 训练模型
```
# 决策树
from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion='entropy')
clf.fit(X_train, y_train)
train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)

print("train score:{0}; test_score:{1}".format(train_score,test_score))
```
```
def cv_score(depth):
    clf = DecisionTreeClassifier(max_depth=depth)
    clf.fit(X_train, y_train)
    tr_score = clf.score(X_train, y_train)
    cv_score = clf.score(X_test, y_test)
    
    return tr_score, cv_score

depths = range(2, 15)
scores = [cv_score(depth) for depth in depths]
tr_scores = [s[0] for s in scores]
cv_scores = [s[1] for s in scores]

# 找出交叉验证评分最高的索引
best_score_index = np.argmax(cv_scores)
best_score = cv_scores[best_score_index]

best_param = depths[best_score_index]

%matplotlib inline
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4), dpi=96)
plt.grid()
plt.xlabel("decision tree max depth")
plt.ylabel("score")

plt.plot(depths, cv_scores, 'g-', label='test score')
plt.plot(depths, tr_scores, 'r--', label='train score')

plt.legend()
plt.show()

print("最好的参数：{0}，最好的分数：{1}".format(best_param, best_score))
```
![image.png](https://upload-images.jianshu.io/upload_images/17476267-3e46a1d9c553b63b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


```
def cv_score_gini(val):
    clf = DecisionTreeClassifier(criterion='gini', min_impurity_decrease=val)
    clf.fit(X_train, y_train)
    tr_score = clf.score(X_train, y_train)
    cv_score = clf.score(X_test, y_test)
    
    return tr_score, cv_score

values = np.linspace(0,0.5, 1000)
scores = [cv_score_gini(val) for val in values]
tr_scores = [s[0] for s in scores]
cv_scores = [s[1] for s in scores]

# 找出交叉验证评分最高的索引
best_score_index = np.argmax(cv_scores)
best_score = cv_scores[best_score_index]

best_param = values[best_score_index]

%matplotlib inline
import matplotlib.pyplot as plt

plt.figure(figsize=(6, 4), dpi=96)
plt.grid()
plt.xlabel("threshold of entropy")
plt.ylabel("score")

plt.plot(values, cv_scores, 'g-', label='test score')
plt.plot(values, tr_scores, 'r--', label='train score')

plt.legend()
plt.show()

print("最好的参数：{0}，最好的分数：{1}".format(best_param, best_score))
```
![image.png](https://upload-images.jianshu.io/upload_images/17476267-307633f47562b793.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

```
from sklearn.model_selection import GridSearchCV
entropy_thresholds = np.linspace(0, 1, 50)
gini_thresholds = np.linspace(0, 0.5, 50)

# 设置参数矩阵
param_grid = [
    {"criterion":['entropy'], 'min_impurity_decrease': entropy_thresholds},
    {"criterion":['gini'], 'min_impurity_decrease': entropy_thresholds},
    {"max_depth": range(2, 15)},
    # 每个节点最小样本数量
    {"min_samples_leaf":range(2, 30, 2)}
]

clf = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
clf.fit(X, y)

print("最好的参数：{0}\n最好的分数：{1}".format(clf.best_params_, clf.best_score_))
```
```
clf = DecisionTreeClassifier(criterion='entropy', max_depth=2, min_samples_leaf=8)
clf.fit(X_train, y_train)

train_score = clf.score(X_train, y_train)
test_score = clf.score(X_test, y_test)
print("train score:{0}; test_score:{1}".format(train_score,test_score))
```
```
import joblib
joblib.dump(clf, 'clf_model_ver001.pkl')
```
```
# 逻辑回归
from sklearn.linear_model import LogisticRegression
logistic_reg = LogisticRegression()
logistic_reg.fit(X_train, y_train)

train_score = logistic_reg.score(X_train, y_train)
test_score = logistic_reg.score(X_test, y_test)
print("train score:{0}; test_score:{1}".format(train_score,test_score))
```

```
import joblib
joblib.dump(logistic_reg, 'logistic_reg_model_ver001.pkl')
```
```
# 岭回归
from sklearn.linear_model import Ridge
ridge_reg = Ridge(alpha=0.5)
ridge_reg.fit(X_train, y_train)

train_score = ridge_reg.score(X_train, y_train)
test_score = ridge_reg.score(X_test, y_test)
print("train score:{0}; test_score:{1}".format(train_score,test_score))
```
```
joblib.dump(ridge_reg, 'ridge_reg_model_ver001.pkl')
```
```
# 神经网络
import tensorflow as tf

X_holder = tf.placeholder(tf.float32)
y_holder = tf.placeholder(tf.float32)

def addConnect(inputs, in_size, out_size, activation_function=None):
    Weights = tf.Variable(tf.truncated_normal([in_size, out_size], stddev=0.01))
    biases = tf.Variable(tf.zeros([1, out_size]))
    Wx_plus_b = tf.matmul(inputs, Weights) + biases
    if activation_function is None:
        return Wx_plus_b
    else:
        return activation_function(Wx_plus_b)

layer_1 = addConnect(X_holder, 10, 10, tf.nn.relu)
layer_2 = addConnect(layer_1, 10, 10, tf.nn.relu)
predict_y = addConnect(layer_2, 10, 1, tf.nn.sigmoid)

loss = tf.reduce_mean(-tf.reduce_sum(y_holder * tf.log(predict_y), 1))
optimizer = tf.train.AdagradOptimizer(0.3)
train = optimizer.minimize(loss)

session = tf.Session()
init = tf.global_variables_initializer()
session.run(init)

for i in range(500):
    features, labels = X_train[i*100: (i+1)*100], y_train[i*100: (i+1)*100].reshape(-1, 1)
    session.run(train, feed_dict={X_holder:features, y_holder:labels})
    if i % 50 == 0:
        correct_prediction = tf.equal(tf.argmax(predict_y, 1), tf.argmax(y_holder, 1))
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
        accuracy_value = session.run(accuracy, feed_dict={X_holder:X_test, y_holder:y_test.reshape(-1, 1)})
        print('step:%d accuracy:%.4f' % (i, accuracy_value))   
```
```
def save_model(session, model_name):
    saver = tf.train.Saver()
    save_path = saver.save(session, './models/{}.ckpt'.format(model_name))
    print('Save to path:', save_path)
    
save_model(session, "nn_ver001")
```
```
import os
from tensorflow.python.client import device_lib
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "99"
 
if __name__ == "__main__":
    print(device_lib.list_local_devices())
```
